{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "O0LW4w6B8s7u"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "db_path = 'films.db'\n",
        "json_path = 'films.json'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getHTMLdocument(url):\n",
        "    response = requests.get(url)\n",
        "    return response.content"
      ],
      "metadata": {
        "id": "3wb-b5ntN3rR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions for extracting \"country\" from the url"
      ],
      "metadata": {
        "id": "43wS3ktgN-Ki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_alphabetic_substring(text):\n",
        "    if text[:13] == 'United States':\n",
        "        return 'United States'\n",
        "    if text[:14] == 'United Kingdom':\n",
        "        return 'United Kingdom'\n",
        "    for i, char in enumerate(text):\n",
        "        if not char.isalpha() and char != ' ':\n",
        "            return text[:i]\n",
        "    return text\n",
        "\n",
        "def get_country_from_movie_page(movie_url):\n",
        "    movie_html = getHTMLdocument(movie_url)\n",
        "    movie_soup = BeautifulSoup(movie_html, 'html.parser')\n",
        "    infobox = movie_soup.find('table', {'class': 'infobox'})\n",
        "    if infobox:\n",
        "        rows = infobox.find_all('tr')\n",
        "        for row in rows:\n",
        "            header = row.find('th')\n",
        "            if header and ('Country' in header.get_text() or 'Countries' in header.get_text()):\n",
        "                country_td = row.find('td')\n",
        "                if country_td:\n",
        "                    return extract_alphabetic_substring(country_td.get_text(strip=True))\n",
        "    return \"Country not found\"\n",
        "\n"
      ],
      "metadata": {
        "id": "rDDgx4VW9wW3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Functions for extracting \"directors\" from the url"
      ],
      "metadata": {
        "id": "tNQFvmM_OP5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_director_name(name):\n",
        "    return re.sub(r'([a-z])([A-Z])', r'\\1 \\2', name)\n",
        "\n",
        "def get_director_from_movie_page(movie_url):\n",
        "    movie_html = getHTMLdocument(movie_url)\n",
        "    movie_soup = BeautifulSoup(movie_html, 'html.parser')\n",
        "    infobox = movie_soup.find('table', {'class': 'infobox'})\n",
        "    if infobox:\n",
        "        rows = infobox.find_all('tr')\n",
        "        for row in rows:\n",
        "            header = row.find('th')\n",
        "            if header and 'Directed by' in header.get_text():\n",
        "                director_td = row.find('td')\n",
        "                if director_td:\n",
        "                    return format_director_name(director_td.get_text(strip=True))\n",
        "    return \"Director not found\"\n"
      ],
      "metadata": {
        "id": "EO4olsFSN9K2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to fetch the films and return data with all attributes as a list:"
      ],
      "metadata": {
        "id": "EfRBG8RWOlkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_films():\n",
        "    url_to_scrape = \"https://en.wikipedia.org/wiki/List_of_highest-grossing_films\"\n",
        "    html_document = getHTMLdocument(url_to_scrape)\n",
        "    soup = BeautifulSoup(html_document, 'html.parser')\n",
        "    table = soup.find('table', {'class': 'wikitable'})\n",
        "    films_data = []\n",
        "    for row in table.find_all('tr')[1:]:\n",
        "        movie_title, revenue, year, country, directors = None, None, None, \"Unknown\", \"Unknown\"\n",
        "        cnt = 0\n",
        "        for i in row.find_all('td'):\n",
        "            cnt += 1\n",
        "            if cnt == 3:\n",
        "                revenue = re.sub(r'[^\\d]', '', i.get_text(strip=True))\n",
        "            if cnt == 4:\n",
        "                year = i.get_text(strip=True)\n",
        "        movie_name_tag = row.find('th')\n",
        "        if movie_name_tag:\n",
        "            movie_link = movie_name_tag.find('a')\n",
        "            if movie_link:\n",
        "                movie_title = movie_link.get_text(strip=True)\n",
        "                movie_url = \"https://en.wikipedia.org\" + movie_link.get('href')\n",
        "                country = get_country_from_movie_page(movie_url)\n",
        "                directors = get_director_from_movie_page(movie_url)\n",
        "        if movie_title and revenue and year:\n",
        "            films_data.append((movie_title, directors, int(year), int(revenue), country))\n",
        "    return films_data"
      ],
      "metadata": {
        "id": "6U1kn4X6OiFb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to take listed data and put to database"
      ],
      "metadata": {
        "id": "s0F616s5OtKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_database(films_data):\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('DROP TABLE IF EXISTS films')\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE films (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            title TEXT,\n",
        "            directors TEXT,\n",
        "            year INTEGER,\n",
        "            revenue INTEGER,\n",
        "            country TEXT\n",
        "        )\n",
        "    ''')\n",
        "    cursor.executemany('INSERT INTO films (title, directors, year, revenue, country) VALUES (?, ?, ?, ?, ?)', films_data)\n",
        "    conn.commit()\n",
        "    conn.close()"
      ],
      "metadata": {
        "id": "iDE4eP4qOk5a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Eventially we can get a json data from database:"
      ],
      "metadata": {
        "id": "38HIFtSuPAgo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_from_database():\n",
        "    conn = sqlite3.connect(db_path)\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('SELECT title, directors, year, revenue, country FROM films')\n",
        "    films_data = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return films_data\n",
        "\n",
        "def save_to_json(films_data):\n",
        "    films_list = [\n",
        "        {'title': film[0], 'directors': film[1], 'year': film[2], 'revenue': film[3], 'country': film[4]}\n",
        "        for film in films_data\n",
        "    ]\n",
        "    with open(json_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(films_list, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "def main():\n",
        "    films_data = fetch_films()\n",
        "    save_to_database(films_data)\n",
        "\n",
        "    films_data_from_db = fetch_from_database()\n",
        "    save_to_json(films_data_from_db)\n",
        "\n",
        "    print(\"Films data has been stored in the database and saved to JSON.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcbgir8aPa6k",
        "outputId": "e44e4ae3-5d7c-49b9-8762-e380e46c9e6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Films data has been stored in the database and saved to JSON.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QajdbW_RPbBF"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}